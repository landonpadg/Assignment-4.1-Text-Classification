{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "#from text_functions_solutions import clean_tokenize, get_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" exercise. First, we'll pull in the text \n",
    "for each party and prepare it for use in Naive Bayes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('conventions',)]\n"
     ]
    }
   ],
   "source": [
    "convention_cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = convention_cur.fetchall()\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'party', 'TEXT', 0, None, 0), (1, 'night', 'INTEGER', 0, None, 0), (2, 'speaker', 'TEXT', 0, None, 0), (3, 'speaker_count', 'INTEGER', 0, None, 0), (4, 'time', 'TEXT', 0, None, 0), (5, 'text', 'TEXT', 0, None, 0), (6, 'text_len', 'TEXT', 0, None, 0), (7, 'file', 'TEXT', 0, None, 0)]\n"
     ]
    }
   ],
   "source": [
    "convention_cur.execute(\"PRAGMA table_info(conventions);\")\n",
    "columns = convention_cur.fetchall()\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_data = []\n",
    "\n",
    "# fill the above list up with items that are themselves lists. The \n",
    "# sublists will have two elements. The first element in the sublist\n",
    "# should be the speech in a single string. The second element\n",
    "# of the sublist should be the party. \n",
    "\n",
    "query_results = convention_cur.execute(\n",
    "                            '''\n",
    "                            SELECT text, party\n",
    "                            FROM conventions\n",
    "                            WHERE party != 'Other';\n",
    "                            ''')\n",
    "\n",
    "for row in query_results :\n",
    "    speech_text, party = row\n",
    "    convention_data.append([speech_text, party])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's a best practice to close up your DB connection when you're done\n",
    "convention_db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['How is your family going.', 'Democratic'],\n",
       " ['Great.', 'Republican'],\n",
       " ['For me, the most important issue is jobs. We need to be able to pay our bills. I trust Donald Trump on jobs way more than I do Joe Biden. There is no doubt that Donald Trump has built the strongest economy we’ve ever seen and I know that he will do it again. Joe Biden doesn’t have the energy and his ideas like raising taxes, it’s going to hurt us. Electing Joe Biden as the president is a huge risk and I don’t want the future of my son in the hands of Joe Biden. I want my son to be able to go out and get a good education. I want the economy to be strong. I want the country that he lives in to be safe and I want our borders to be secure and I don’t want that in Joe Biden’s hands. Donald Trump has built the strongest economy we’ve ever seen, he has made our country safe and as a mom, those are things that I’m very proud of and those are things that are very important to me when I’m looking for a president. I am sticking with Donald Trump.',\n",
       "  'Republican'],\n",
       " ['After she was shot and on the floor, she crawled over to another student, a freshman girl to protect her. She draped her body over her and then the scumbag gunman shot my daughter at point blank range five more times killing Meadow and the girl she was shielding. She had a whole life ahead of her and in that life, she could have done anything and been anything. So many moments that I waited so long for were taken from me. I didn’t get to drop her off at college. I didn’t get to walk her down the aisle, but every moment was taken from her, and for what.',\n",
       "  'Republican'],\n",
       " ['She gave 100% from her energy to the students. She’s a great teacher.',\n",
       "  'Democratic']]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time for our final cleaning before modeling. Go through `conv_sent_data` and take the following steps: \n",
    "\n",
    "1. Tokenize on whitespace\n",
    "1. Remove punctuation\n",
    "1. Remove tokens that fail the `isalpha` test\n",
    "1. Remove stopwords\n",
    "1. Casefold to lowercase\n",
    "1. Join the remaining tokens into a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()\n",
    "\n",
    "convention_data = []\n",
    "\n",
    "# fill the above list up with items that are themselves lists. The \n",
    "# sublists will have two elements. The first element in the sublist\n",
    "# should be the speech in a single string. The second element\n",
    "# of the sublist should be the party. \n",
    "\n",
    "query_results = convention_cur.execute(\n",
    "                            '''\n",
    "                            SELECT text, party\n",
    "                            FROM conventions\n",
    "                            WHERE party != 'Other';\n",
    "                            ''')\n",
    "\n",
    "for row in query_results :\n",
    "    speech_text, party = row\n",
    "    convention_data.append([speech_text, party])\n",
    "\n",
    "def clean_tokenize(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    return ' '.join(cleaned_tokens)\n",
    "    cleaned_tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "\n",
    "for row in query_results:\n",
    "    speech_text = row[0]  \n",
    "    party = row[1]  \n",
    "    \n",
    "    cleaned_speech = clean_tokenize(speech_text)\n",
    "    \n",
    "    convention_data.append([cleaned_speech, party])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, let's make our function to turn these into features. First we need to build our list of candidate words. I started my exploration at a cutoff of 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['This November, we stand at a crossroad. Mobs torch our cities while popular members of Congress promote the same socialism that my father fought against in World War II. We have a Democratic candidate for president who says that I’m not black if I don’t vote for him. Now more than ever, we need leaders who stand by their principles, they won’t compromise their values for political opportunities. Now more than ever, we need leaders who will stand up to the lawlessness supported by the radical left. This November, we have an opportunity to reject the mob mentality and once again be the America that my great great grandfather believed in. During the Trump administration, business ownership among blacks, Hispanics, and females have reached all time highs. Those same groups enjoyed record low unemployment and unprecedented prosperity, and we’re just getting started. I ran for Congress because we don’t need more career politicians, we need a few more chimney sweeps. We need more leaders like president Trump, who understand the freedoms that make up the fabric of America. My fellow Americans, specifically my Democrat and Independent friends, it is now time for us to unite and put aside partisan barriers. Help us win back the House, keep the Senate and give our president four more years, and I promise you we will make you proud. Thank you, and God bless the United States of America.',\n",
       "  'Republican'],\n",
       " ['Thank you Lorraine and Jim. We will now hear from the co-chairs of the Rules Committee, Maria Cardona and Congressman Barney Frank to present that committee’s report.',\n",
       "  'Democratic'],\n",
       " ['Thank you to all our delegations. I’m pleased to announce that vice president Joe Biden has officially been nominated by the democratic party as our candidate for President of the United States. Vice President Biden is hereby invited to deliver an acceptance speech?',\n",
       "  'Democratic'],\n",
       " ['Thank you so much for being a part of this night. As Dr. Biden just reminded us, Joe is a steady and experienced leader who can bring us together and help us heal. He will support us in getting better. Remember we bend the arc of justice. If we participate, if we vote, this moment isn’t beyond you. It’s up to you. Tomorrow night, we’ll meet Joe Biden’s choice for vice president, Kamala Harris and learn more about their vision for the future of our country. And we’ll also hear from Senator Elizabeth Warren and President Barack Obama, plus performances from Billie Eilish and Jennifer Hudson. And now with his song Never Break, here’s John Legend.',\n",
       "  'Democratic'],\n",
       " ['I have always loved the sounds of a classroom. The quiet that sparks with possibility just before students shuffle in, the murmur of ideas bouncing back and forth as we explore the world together. The laughter and tiny moments of surprise you find in materials you’ve taught a million times. When I taught English here at Brandywine high school, I would spend my summer preparing for the school year about to start filled with anticipation. But this quiet is heavy. You can hear the anxiety that echoes down empty hallways. There’s no scent of new notebooks or freshly waxed floors. The rooms are dark as the bright young faces that should fill them are now confined to boxes on a computer screen. I hear it from so many of you, the frustration of parents juggling work while they support their children’s learning are afraid that their kids might get sick from school. The concern of every person working without enough protection, the despair in the lines that stretch out before food banks, and the indescribable sorrow that follows every lonely last breath when the ventilators turn off. Dr.',\n",
       "  'Democratic']]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 0 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in clean_conv_sent_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "def conv_features(text, fw):\n",
    "    ret_dict = dict()\n",
    "    tokens = text.split()\n",
    "    for token in tokens:\n",
    "        if token in fw:\n",
    "            ret_dict[token] = True\n",
    "    return ret_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(\u001b[38;5;28mlen\u001b[39m(feature_words) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(conv_features(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobama was the president\u001b[39m\u001b[38;5;124m\"\u001b[39m, feature_words) \u001b[38;5;241m==\u001b[39m\n\u001b[1;32m      3\u001b[0m        {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobama\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpresident\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m})\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(conv_features(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msome people in america are citizens\u001b[39m\u001b[38;5;124m\"\u001b[39m, feature_words) \u001b[38;5;241m==\u001b[39m\n\u001b[1;32m      5\u001b[0m        {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpeople\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamerica\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcitizens\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m})\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert(len(feature_words) > 0)\n",
    "assert(conv_features(\"obama was the president\", feature_words) ==\n",
    "       {'obama': True, 'president': True})\n",
    "assert(conv_features(\"some people in america are citizens\", feature_words) ==\n",
    "       {'people': True, 'america': True, 'citizens': True})\n",
    "\n",
    "print(\"All assertions passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.616\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Naive Bayes Classifier: 61.60%\n"
     ]
    }
   ],
   "source": [
    "accuracy = nltk.classify.accuracy(classifier, test_set)\n",
    "print(f\"Accuracy of the Naive Bayes Classifier: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "I had a lot of trouble with this code, due to errors with my machine running. With the point I was able to run it to, the Naive Bayes Classifier ran with an accuracy of 61.60%. The model accurately separates Democratic and Republicans based on text features nearly 62% of the time. This definitely would need some fine tuning before being deployed. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute('''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "for row in results:\n",
    "    tweet_text = row[2]  # tweet_text\n",
    "    party = row[1]  # party affiliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tokenize(text):\n",
    "    if isinstance(text, bytes):\n",
    "        text = text.decode('utf-8')\n",
    "    \n",
    "    text = text.lower()  \n",
    "    tokens = text.split()  \n",
    "    \n",
    "   \n",
    "    cleaned_tokens = [token for token in tokens if token.isalpha() and token not in stop_words]\n",
    "    \n",
    "    return ' '.join(cleaned_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data) :\n",
    "    tweet, party = tp    \n",
    "    # Now do the same thing as above, but we store the results rather\n",
    "    # than printing them. \n",
    "   \n",
    "    # get the estimated party\n",
    "    estimated_party = \"Gotta fill this in\"\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "_Write a little about what you see in the results_ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
